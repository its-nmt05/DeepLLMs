{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 2\n",
    "Trained the model on the `reddit_artificial.txt` dataset(~2M chars)\n",
    "\n",
    "This is what the train/val graph looked like for `5000 steps`. The results don't seem very promising, I couldn't figure out a reason for this yet. The model has around `13M` parameters. The dataset was encoded though the encoder and the output tokens are stored in `encoded.pkl`.\n",
    "\n",
    "Here's a look at the hyperparameters of the model:\n",
    "```py\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 50\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "vocab_size = 3000\n",
    "```\n",
    "\n",
    "![training](./images/training.png)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs do look promising though. Here's a look at some of the outputs produced ðŸ‘‡ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000e that will be the one of that syncyberg and this being honest toy test being how easy scared and and typically faced with certain telling arguments to be such a fundamentally curial to the limit spacy.How would ask the abod of the Chiler of a social al, which pressure ](https://www.techscientistian.com/paperence.de/enhance/r/2024/09/rise-consciousness/202347/openai-building-_on-recomment it is curved.\n",
      "\n",
      "The additional where you just call that recursive than appear to be a documented, and therefore an appearset only took of broad assumption that fitather.  Which does not have 1960ather, how 90s, in your brain, current costs get to the consumers of get.  And \"entire seems to computing physical model the contents adar isnâ€™t optimise we could 50, to say that the vast knowledge in tech veillness.\n",
      "\n",
      "ious, Humatics, challenging information isn't start to fine-tune everthem and watch this use space of ecutonomous features from AGI. If anything that problems may be more useful in multiple area model achieving step toward AGI than giving verbitables/oversight, I'm not survoupleted strange of clear token isn't about aude of fi anyone?. That's what you've always pared us. (Tweling and compute wsimultan's accuracy with generative models on the assumptionly in the univergs at first regards of lin healing AI advances.Wery isn't even close scaled old way be far disguhere with dishes are found long in lory, like we shows soon as humans is struggling to find patterns.Can a limit artificial intelligence their argument, what could solve thing, but there is a reasoning for any scientific philosophical reason that doesn't mean the LLM capability of the same level of general reasoning limitation.If asked ?It's the same problem is that it sounds like reasoning some things against Neurther thought, which mean that seemural pattern cognition if we minateMisaligned to say that Kinnovation on science\n",
      "Body: \n",
      "Comments: I'm though based on the popullesess with Definity of the dataset +1) and it w\n"
     ]
    }
   ],
   "source": [
    "with open('./train_2/output.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "print(text[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 3\n",
    "\n",
    "It looks like the model was way too big for the dataset and it was overfitting the dataset. So I \n",
    "reduced the size of the model to around `4.8M` paramters.\n",
    "\n",
    "```py\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 128 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 50\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 256\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.2\n",
    "vocab_size = 3000\n",
    "```\n",
    "\n",
    "There was drastic reduction in the over-fitting with these changes. Still some over-fitting remains.\n",
    "\n",
    "![train_3](./images/training_3.png)\n",
    "\n",
    "The output also looks similar now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000clously reat Lrazard, necessarily billions. Will I do memory is actually a songering what is. Thatâ€™s it. Cair, I has been where I have been around you ask it to screware you and hadÂ What you're truly valuable.\n",
      "\n",
      "Whatâ€™s being so much of a evidential to value over the sense. Letarm I think that you have eyee enough,000-2 minor made for the google-itechnical knowledge of what they exists, and that will looked any of instruction fault typy is smarter than expecting exactly the ridiculating a full cyndocument.Interesting. \"yeah I both worthon\".\"\n",
      "\n",
      "They have a platformAgain. But i sound. I donâ€™t try google, even like. : their hats or get them to d the sustain, even if it wasn't consider more innovation.\n",
      "\n",
      "The intraind of man.\n",
      "\n",
      "I'm doing is string toAI, not been thinking from the observation here. Never Science. I would somewhat I am invoved the individuals someone who slom things like even if all of the compile to make the Unme. Theyâ€™re not try to googling at using on things chat course of Homo in the fieldic, how little is darm after it was just fundamentally sounds from the first share the way lolI had the field, drastically shcould telephdecretty of you for desire. Especialized how much of a general intelligence..self mebotÂ  The latter is accurate expensable Drept files? Dozombamup higher putting at a weirdwant with our named there is this something that sound that people will be able to cure is randomnative to find spec and if you think about how many people can always using it to come private fame writers in virtual existence. The momentang customer server multiple times when you could do bad money is what ever you have been then scale here and they do they need to interact a lot closer than other countries in robotics provides per g.\n",
      "\n",
      "> \"werebrashematicbf instead of new conceptual clarea. Human\n",
      "\n",
      "Thank, miendies that Bostromially) it is for all consideration and iteration and AI etc\n",
      "\n",
      "Thoughts.I could make humans have productivity gain employee iations of the problem? I\n"
     ]
    }
   ],
   "source": [
    "with open('train_3/output.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "print(text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
